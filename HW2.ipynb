{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1b8ac10b-db82-44d5-8687-23d9dc778079",
   "metadata": {},
   "source": [
    "Your Name: Vaibhav Shrivastav\n",
    "Your ASU ID: 1229620381"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82745e9-05a0-42eb-acd5-8398ca7d586e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Homework Assignment 2 - A Probablistic Naive Bayes Classifier\n",
    "\n",
    "CSE 575 Section C Fall 2024 Luo\n",
    "\n",
    "## Description\n",
    "\n",
    "**This is an individual work.** The project focuses on a subset of the MNIST dataset containing images of digits \"0\" and \"1\". The project involves four tasks: feature extraction, parameter calculation, implementation of Na√Øve Bayes classifiers, and prediction of labels for the test data using the classifiers. Finally, calculating the accuracy of the predictions.\n",
    "\n",
    "## What packages are allowed / prohibited\n",
    "\n",
    "You ARE allowed to use fundamental math/stat operators in numpy and math, such as numpy.var, numpy.std, numpy.mean and etc.\n",
    "\n",
    "You are <font color=\"red\">**NOT allowed**</font> to use functions that directly return Gaussian-dsitribution PDF values or directly use a NB classifier, e.g. scipy.stat.norm, numpy.random.normal, the sklearn library as a whole, or the likes. If we find you use any of those in your source code, your submission will be desk-rejected (receiving a 0). \n",
    "\n",
    "## Deliverables\n",
    "\n",
    "- (7 pts) Your source code in this **HW2.ipynb** that contains all the proper implementations\n",
    "- (3 pts) A one-page **pdf** report, excluding the cover page if you have one. **You will report all output values (from Step 2 and Step 3) for all the 3 cases given to you**, and record any difficulty or problem you have encountered during the process.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The ground truths for the given 3 cases will be revealed on Canvas **by Tuesday, Feb 13th**. During grading, we will further assess your program and see if it can pass 2 additional hidden test cases. \n",
    "\n",
    "The error range for the PDF values in Step 2 is +-0.2, and the error range for the accuracies in Step 3 is +-0.005 .\n",
    "\n",
    "## Deadline\n",
    "\n",
    "2359 hours on Tuesday, Feb 20th aka the Midterm 1 day. No late submissions will be accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ea208e78-5da4-4457-ac55-a9e9ff1d189e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the necessary libraries and data\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import math\n",
    "\n",
    "# Loading the training set and the test set given a case number\n",
    "\n",
    "case = 1 # can also be 0, 1, or 2\n",
    "\n",
    "Numpyfile0 = scipy.io.loadmat(f'./data/train{case}/digit0_stu_train{case}.mat')\n",
    "Numpyfile1 = scipy.io.loadmat(f'./data/train{case}/digit1_stu_train{case}.mat')\n",
    "Numpyfile2 = scipy.io.loadmat('./data/test/digit0_testset.mat')\n",
    "Numpyfile3 = scipy.io.loadmat('./data/test/digit1_testset.mat')\n",
    "\n",
    "train0 = Numpyfile0.get('target_img') # Training samples of digit 0\n",
    "train1 = Numpyfile1.get('target_img') # Training samples of digit 1\n",
    "\n",
    "test0 = Numpyfile2.get('target_img') # Test samples of digit 0\n",
    "test1 = Numpyfile3.get('target_img') # Test samples of digit 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df55833-0235-49e2-ba98-b9a7375f73dc",
   "metadata": {},
   "source": [
    "# 1. Feature Extraction - Transforming the Raw Images into 2D\n",
    "\n",
    "The images of MNIST in its raw form are all 28x28 greyscale pixel values, or 1x784 if flattened. That is way too many dimensions! How can we find a way to represent the images but with far fewer dimensions?\n",
    "\n",
    "For this project, we will transform all image samples into 2D vectors. You need to first extract features from your original training sets **i.e. train0, train1**, by converting the original data arrays to 2D arrays. The two features out of any image x are defined as following: \n",
    "\n",
    "**Feature1 / x_f1:** The average brightness of each image (average all pixel values within a whole image array). \n",
    "\n",
    "**Feature2 / x_f2:** The standard deviation of the brightness of each image (standard deviation of all pixel brightness values within a whole image array). \n",
    "\n",
    "We assume that these two features are i.i.d and are sampled from Gaussian distributions with regard to all images. Below is a function template you may make use of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8ca58177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Visualizing Dataset')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].imshow(train0[0], cmap = 'gray')\n",
    "axs[1].imshow(train1[0], cmap = 'gray')\n",
    "axs[0].set_title('Digit 0')\n",
    "axs[1].set_title('Digit 1')\n",
    "fig.suptitle('Visualizing Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "2ad14ce9-e919-4e9c-a4e4-b22198db5093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difficulty encountered - None\n"
     ]
    }
   ],
   "source": [
    "# Step 1 Template (you are free to modify it at will)\n",
    "\n",
    "def feat_extract(x):\n",
    "    assert x.shape == (28, 28)\n",
    "    # do some feature extraction here\n",
    "    x_f1 = np.mean(x)\n",
    "    x_f2 = np.std(x)\n",
    "    \n",
    "    return x_f1, x_f2\n",
    "print('Difficulty encountered - None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b499a94b-8222-4ce5-a7b0-ceeffa056e41",
   "metadata": {},
   "source": [
    "# 2. The NB Likehood Parameters are Distributed as Gaussian PDFs\n",
    "\n",
    "You need to calculate all the parameters for our two-class Naive Bayes (NB) classifier respectively, based upon the 2-D featurized data you have obtained in Step 1. \n",
    "\n",
    "**Assuming the two priors P(Y = 0) = P(Y = 1) = 0.5**, we now need to figure out **4 sets of Gaussian PDFs** for the 4 likelihood parameters in order to make predictions. **Remember, you obtain the parameters only from the training sets**:  \n",
    "\n",
    "1. Mean of Feature1 for digit0 \n",
    "2. Variance of Feature1 for digit0 \n",
    "3. Mean of Feature2 for digit0 \n",
    "4. Variance of Feature2 for digit0 \n",
    "5. Mean of Feature1 for digit1\n",
    "6. Variance of Feature1 for digit1 \n",
    "7. Mean of Feature2 for digit1 \n",
    "8. Variance of Feature2 for digit1 \n",
    "\n",
    "**At the end of this step, you need to print out a list that contains these 8 values in the above order.**\n",
    "\n",
    "Hint: Double check the NB classifier formula, what exactly are the 4 likelihood parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2593a425-2c77-4815-adb0-87ff6d6c14cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difficulty Encountered - Made mistakes in implementing the formula for gaussian pdf several times!\n",
      "      Initially I had used a for loop to calculate all the values, thereafter I have constricted each calculation to using inline for loops\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_f1_digit0</th>\n",
       "      <th>var_f1_digit0</th>\n",
       "      <th>mean_f2_digit0</th>\n",
       "      <th>var_f2_digit0</th>\n",
       "      <th>mean_f1_digit1</th>\n",
       "      <th>var_f1_digit1</th>\n",
       "      <th>mean_f2_digit1</th>\n",
       "      <th>var_f2_digit1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>case0</th>\n",
       "      <td>44.214643</td>\n",
       "      <td>115.550259</td>\n",
       "      <td>87.430595</td>\n",
       "      <td>101.468803</td>\n",
       "      <td>19.411020</td>\n",
       "      <td>32.700344</td>\n",
       "      <td>61.386556</td>\n",
       "      <td>84.803712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case1</th>\n",
       "      <td>44.318015</td>\n",
       "      <td>114.934834</td>\n",
       "      <td>87.539378</td>\n",
       "      <td>100.723410</td>\n",
       "      <td>19.409105</td>\n",
       "      <td>30.990618</td>\n",
       "      <td>61.431762</td>\n",
       "      <td>81.506435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case2</th>\n",
       "      <td>44.153454</td>\n",
       "      <td>113.586457</td>\n",
       "      <td>87.395606</td>\n",
       "      <td>100.333752</td>\n",
       "      <td>19.379586</td>\n",
       "      <td>31.234097</td>\n",
       "      <td>61.363748</td>\n",
       "      <td>82.256987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_f1_digit0  var_f1_digit0  mean_f2_digit0  var_f2_digit0  \\\n",
       "case0       44.214643     115.550259       87.430595     101.468803   \n",
       "case1       44.318015     114.934834       87.539378     100.723410   \n",
       "case2       44.153454     113.586457       87.395606     100.333752   \n",
       "\n",
       "       mean_f1_digit1  var_f1_digit1  mean_f2_digit1  var_f2_digit1  \n",
       "case0       19.411020      32.700344       61.386556      84.803712  \n",
       "case1       19.409105      30.990618       61.431762      81.506435  \n",
       "case2       19.379586      31.234097       61.363748      82.256987  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Step 2 Template (you are free to modify it at will)\n",
    "\n",
    "def gaussian_pdf(mu, var, x_f):\n",
    "    # plug in the Gaussian PDF formula, given mean, variance, and a specific feature value x_f\n",
    "    # applies to both feature1 and feature2\n",
    "    numerator = np.exp(-0.5*(((x_f - mu)**2)/var))\n",
    "    denom = np.sqrt(2*np.pi*var)\n",
    "    return numerator/denom\n",
    "\n",
    "# calculate the 4 mean/variance pairs from the featurized train0 and train1 that define the 4 PDFs\n",
    "#f1 is the mean of an image's brightness\n",
    "#f2 is the standard deviation of an image's brightness\n",
    "global case\n",
    "cases = [0, 1, 2]\n",
    "\n",
    "\n",
    "features_df = pd.DataFrame(columns = ['mean_f1_digit0','var_f1_digit0', 'mean_f2_digit0', 'var_f2_digit0', 'mean_f1_digit1', 'var_f1_digit1',\\\n",
    "                                       'mean_f2_digit1', 'var_f2_digit1'])\n",
    "\n",
    "for case in cases:\n",
    "    Numpyfile0 = scipy.io.loadmat(f'./data/train{case}/digit0_stu_train{case}.mat')\n",
    "    Numpyfile1 = scipy.io.loadmat(f'./data/train{case}/digit1_stu_train{case}.mat')\n",
    "    Numpyfile2 = scipy.io.loadmat('./data/test/digit0_testset.mat')\n",
    "    Numpyfile3 = scipy.io.loadmat('./data/test/digit1_testset.mat')\n",
    "\n",
    "    train0 = Numpyfile0.get('target_img') # Training samples of digit 0\n",
    "    train1 = Numpyfile1.get('target_img') # Training samples of digit 1\n",
    "\n",
    "    test0 = Numpyfile2.get('target_img') # Test samples of digit 0\n",
    "    test1 = Numpyfile3.get('target_img') # Test samples of digit 1\n",
    "    \n",
    "    #Digit0 Feature1\n",
    "    mean_f1_digit0 = np.mean(np.fromiter((np.mean(sample) for sample in train0), dtype= 'float'))\n",
    "    var_f1_digit0 = np.var(np.fromiter((np.mean(sample) for sample in train0), dtype = 'float'))\n",
    "\n",
    "    #Digit0 Feature2\n",
    "    mean_f2_digit0 = np.mean(np.fromiter((np.std(sample) for sample in train0), dtype = 'float'))\n",
    "    var_f2_digit0 = np.var(np.fromiter((np.std(sample) for sample in train0), dtype = 'float'))\n",
    "\n",
    "    #Digit1 Feature1\n",
    "    mean_f1_digit1 = np.mean(np.fromiter((np.mean(sample) for sample in train1), dtype= 'float'))\n",
    "    var_f1_digit1 = np.var(np.fromiter((np.mean(sample) for sample in train1), dtype= 'float'))\n",
    "\n",
    "    #Digit1 Feature2\n",
    "    mean_f2_digit1 = np.mean(np.fromiter((np.std(sample) for sample in train1), dtype= 'float'))\n",
    "    var_f2_digit1 = np.var(np.fromiter((np.std(sample) for sample in train1), dtype= 'float'))\n",
    "    \n",
    "    features_df.loc['case'+ str(len(features_df))] = [mean_f1_digit0, var_f1_digit0,\n",
    "        mean_f2_digit0, var_f2_digit0,\n",
    "        mean_f1_digit1, var_f1_digit1,\n",
    "        mean_f2_digit1, var_f2_digit1]\n",
    "\n",
    "print('Difficulty Encountered - Made mistakes in implementing the formula for gaussian pdf several times!\\n\\\n",
    "      Initially I had used a for loop to calculate all the values, thereafter I have constricted each calculation to using inline for loops')\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb270c1-9071-4a5e-8d54-268731daa5ea",
   "metadata": {},
   "source": [
    "# 3. NB Predictions and Accuracies out of the Test Sets\n",
    "\n",
    "Once Step 1 and Step 2 are finished, you now have everything to generate predictions for samples in our test sets. We have two test sets in this project: **test0** of all digit 0's, and **test1** of all digit 1's.\n",
    "\n",
    "Your prediction using a NB classifier is by comparing the two posteriors - P(Y=0|X) vs. P(Y=1|X). For a single test set image X in its raw form, you will obtain the two posteriors by doing \n",
    "\n",
    "1. Convert X into the same feature1-feature2 vectors with your feature extractor done in Step 1, then\n",
    "2. Use the 4 established Gaussian PDFs from Step 2 to obtain the two posteriors and make judgements.\n",
    "\n",
    "**At the end of this step, you need to print out a two-item list that contains the overall prediction accuracies for test0 and test1. The accuracy values should both be within 0 and 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "264feed4-a3c9-4737-8aab-21dc08395696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difficulty encountered - I had to gain a good understanding of what exactly we are trying to do, connect the dots between Feature extraction,\n",
      "      Naives Bayes and PDF. Went through the lecture notes from CSE229 Stanford Course, which helped, went through our lecture slides few times as well\n",
      "      Calculation itself is fairly simple.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc0</th>\n",
       "      <th>acc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>case0</th>\n",
       "      <td>0.916327</td>\n",
       "      <td>0.923348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case1</th>\n",
       "      <td>0.917347</td>\n",
       "      <td>0.923348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case2</th>\n",
       "      <td>0.917347</td>\n",
       "      <td>0.923348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc0      acc1\n",
       "case0  0.916327  0.923348\n",
       "case1  0.917347  0.923348\n",
       "case2  0.917347  0.923348"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3 Template (you are free to modify it at will)\n",
    "cases = [0, 1, 2]\n",
    "pdf_df = pd.DataFrame(columns = ['acc0', 'acc1'])\n",
    "for case in cases:\n",
    "    # print(case)\n",
    "    Numpyfile0 = scipy.io.loadmat(f'./data/train{case}/digit0_stu_train{case}.mat')\n",
    "    Numpyfile1 = scipy.io.loadmat(f'./data/train{case}/digit1_stu_train{case}.mat')\n",
    "    Numpyfile2 = scipy.io.loadmat('./data/test/digit0_testset.mat')\n",
    "    Numpyfile3 = scipy.io.loadmat('./data/test/digit1_testset.mat')\n",
    "\n",
    "    test0 = Numpyfile2.get('target_img') # Test samples of digit 0\n",
    "    test1 = Numpyfile3.get('target_img') # Test samples of digit 1\n",
    "\n",
    "    correct0 = 0\n",
    "    correct1 = 0\n",
    "    \n",
    "    for x in test0:\n",
    "        x_f1, x_f2 = feat_extract(x)\n",
    "        # obtain prediction and see if it predicts 0\n",
    "        likelihood0 = gaussian_pdf(features_df.loc['case'+str(case)].mean_f1_digit0, features_df.loc['case'+str(case)].var_f1_digit0, x_f1 )*\\\n",
    "            gaussian_pdf(features_df.loc['case'+str(case)].mean_f2_digit0, features_df.loc['case'+str(case)].var_f2_digit0, x_f2)*0.5\n",
    "        likelihood1 = gaussian_pdf(features_df.loc['case'+str(case)].mean_f1_digit1, features_df.loc['case'+str(case)].var_f1_digit1, x_f1)*\\\n",
    "            gaussian_pdf(features_df.loc['case'+str(case)].mean_f2_digit1, features_df.loc['case'+str(case)].var_f2_digit1, x_f2)*0.5\n",
    "        if likelihood0 > likelihood1:\n",
    "            correct0+=1\n",
    "\n",
    "    acc0 = correct0 / len(test0)\n",
    "    for x in test1:\n",
    "        x_f1, x_f2 = feat_extract(x)\n",
    "        # obtain prediction and see if it predicts 1\n",
    "        likelihood1 = gaussian_pdf(features_df.loc['case'+str(case)].mean_f1_digit1, features_df.loc['case'+str(case)].var_f1_digit1, x_f1)*\\\n",
    "            gaussian_pdf(features_df.loc['case'+str(case)].mean_f2_digit1, features_df.loc['case'+str(case)].var_f2_digit1, x_f2)*0.5\n",
    "        likelihood0 = gaussian_pdf(features_df.loc['case'+str(case)].mean_f1_digit0, features_df.loc['case'+str(case)].var_f1_digit0, x_f1)*\\\n",
    "            gaussian_pdf(features_df.loc['case'+str(case)].mean_f2_digit0, features_df.loc['case'+str(case)].var_f2_digit0, x_f2)*0.5\n",
    "        if likelihood1 > likelihood0:\n",
    "            correct1 += 1\n",
    "    acc1 = correct1 / len(test1)\n",
    "    pdf_df.loc['case'+str(case)] = [acc0, acc1]\n",
    "\n",
    "print('Difficulty encountered - I had to gain a good understanding of what exactly we are trying to do, connect the dots between Feature extraction,\\n\\\n",
    "      Naives Bayes and PDF. Went through the lecture notes from CSE229 Stanford Course, which helped, went through our lecture slides few times as well\\n\\\n",
    "      Calculation itself is fairly simple.')\n",
    "pdf_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
